{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.16.8-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Using cached lxml-5.3.0-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests (from unstructured)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Using cached emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dataclasses-json (from unstructured)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Using cached python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Using cached langdetect-1.0.9-py3-none-any.whl\n",
      "Collecting numpy<2 (from unstructured)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Using cached rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.28.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.17.0-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting tqdm (from unstructured)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from unstructured) (6.1.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Using cached python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
      "  Using cached marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Using cached olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->unstructured)\n",
      "  Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->unstructured)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->unstructured)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->unstructured)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Using cached eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpx>=0.27.0 (from unstructured-client->unstructured)\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pydantic<2.10.0,>=2.9.2 (from unstructured-client->unstructured)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Using cached pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured)\n",
      "  Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27.0->unstructured-client->unstructured)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
      "Downloading unstructured-0.16.8-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached lxml-5.3.0-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Using cached python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Using cached rapidfuzz-3.10.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading unstructured_client-0.28.1-py3-none-any.whl (62 kB)\n",
      "Downloading wrapt-1.17.0-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 2.4/3.2 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 11.8 MB/s eta 0:00:00\n",
      "Using cached eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Using cached marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Using cached pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: webencodings, filetype, wrapt, urllib3, tqdm, soupsieve, sniffio, regex, rapidfuzz, python-magic, python-iso639, pypdf, pydantic-core, pycparser, olefile, numpy, mypy-extensions, marshmallow, lxml, langdetect, jsonpath-python, joblib, idna, html5lib, h11, eval-type-backport, emoji, click, charset-normalizer, chardet, certifi, backoff, annotated-types, aiofiles, typing-inspect, requests, python-oxmsg, pydantic, nltk, httpcore, cffi, beautifulsoup4, anyio, requests-toolbelt, httpx, dataclasses-json, cryptography, unstructured-client, unstructured\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 anyio-4.6.2.post1 backoff-2.2.1 beautifulsoup4-4.12.3 certifi-2024.8.30 cffi-1.17.1 chardet-5.2.0 charset-normalizer-3.4.0 click-8.1.7 cryptography-44.0.0 dataclasses-json-0.6.7 emoji-2.14.0 eval-type-backport-0.2.0 filetype-1.2.0 h11-0.14.0 html5lib-1.1 httpcore-1.0.7 httpx-0.28.0 idna-3.10 joblib-1.4.2 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.3.0 marshmallow-3.23.1 mypy-extensions-1.0.0 nltk-3.9.1 numpy-1.26.4 olefile-0.47 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.10.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 soupsieve-2.6 tqdm-4.67.1 typing-inspect-0.9.0 unstructured-0.16.8 unstructured-client-0.28.1 urllib3-2.2.3 webencodings-0.5.1 wrapt-1.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025E4B1FD600>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network')': /simple/unstructured/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025E4B1FD930>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/unstructured/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025E4B1FDC60>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/unstructured/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000025E4B1FDE10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/unstructured/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from pdfminer.six) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from pdfminer.six) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Using cached pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n",
      "Installing collected packages: pdfminer.six\n",
      "Successfully installed pdfminer.six-20240706\n",
      "Collecting pi-heif\n",
      "  Downloading pi_heif-0.21.0-cp310-cp310-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting pillow>=10.1.0 (from pi-heif)\n",
      "  Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl.metadata (9.3 kB)\n",
      "Downloading pi_heif-0.21.0-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.6/1.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 10.1 MB/s eta 0:00:00\n",
      "Using cached pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "Installing collected packages: pillow, pi-heif\n",
      "Successfully installed pi-heif-0.21.0 pillow-11.0.0\n",
      "Collecting openai\n",
      "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (0.28.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.0-cp310-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\z004j58u\\repos\\others\\ragcookbookloadingdata\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.8.0-cp310-none-win_amd64.whl (206 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.0 openai-1.55.3\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured\n",
    "!pip install pdfminer.six\n",
    "!pip install pi-heif\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unstructured_inference'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# define the path to the pdf file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m pdf_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets/pdf_files/adult_data_article.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\z004j58u\\repos\\others\\RAGCookbookLoadingData\\.venv\\lib\\site-packages\\unstructured\\partition\\pdf.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m PILImage\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentLayout\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured_inference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayoutelement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayoutElement\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_chunking_strategy\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unstructured_inference'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# define the path to the pdf file\n",
    "pdf_file_path = \"../datasets/pdf_files/adult_data_article.pdf\"\n",
    "\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=pdf_file_path,\n",
    "    strategy=\"hi_res\",\n",
    ")\n",
    "\n",
    "\n",
    "# function to extract tables and texts from the raw pdf elements\n",
    "def extract_text_and_tables(raw_pdf_elements):\n",
    "    \"\"\"\n",
    "    This function takes in the raw pdf elements and extracts the tables and texts from the pdf\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    texts = []\n",
    "\n",
    "    # loop through the raw pdf elements and categorize them into tables and texts\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            tables.append(str(element))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            texts.append(str(element))\n",
    "\n",
    "    return texts, tables\n",
    "\n",
    "\n",
    "# extract the tables and texts from the raw pdf elements\n",
    "found_texts, found_tables = extract_text_and_tables(raw_pdf_elements=raw_pdf_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# function to take tables as input and then summarize them\n",
    "def tables_summarize(row):\n",
    "    \"\"\"\n",
    "    This function takes each row of a dataframe and uses a LLM to generate text\n",
    "    summaries to each table (row.table)\n",
    "\n",
    "    Args:\n",
    "        row: pandas dataframe row, including the attribute table\n",
    "    Returns:\n",
    "        table_summaries: text summaries for each table\n",
    "    \"\"\"\n",
    "    summary_prompt = f\"\"\"You are an assistant tasked with summarizing tables. \\\n",
    "                    Give a concise summary of the table. Table chunk: {row.table}\"\"\"\n",
    "\n",
    "    # Initialize the OpenAI client with your API key\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # Create the chat completion using the chosen\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    # Generate and print the response\n",
    "    row[\"table_summary\"] = response.choices[0].message.content\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "# create a pandas dataframe from the tables\n",
    "tables_df = pd.DataFrame(found_tables, columns=[\"table\"])\n",
    "\n",
    "# add a column to the dataframe to store the summaries\n",
    "tables_df = tables_df.apply(tables_summarize, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random question to the embedded table\n",
    "user_question = \"What are the education levels of the people working in Sales?\"\n",
    "\n",
    "\n",
    "def build_prompt_and_generate_answer(user_question, found_table):\n",
    "    \"\"\"\n",
    "    This function builds a prompt using the user's question and the context of the table\n",
    "    and generates an answer using the OpenAI API\n",
    "\n",
    "    Parameters:\n",
    "        user_question: the question asked by the user\n",
    "        found_table: the table context to generate the answer from\n",
    "\n",
    "    Returns:\n",
    "        answered_question: the answer to the user's question\n",
    "    \"\"\"\n",
    "    # define the question prompt\n",
    "    question_prompt = f\"\"\"You are an assistant using the content from PDFs \\\n",
    "                        to answer questions. Below you can find the \\\n",
    "                        user's question and relevant context. Please use the \\\n",
    "                        context to generate an answer to the user's question.\n",
    "                        \n",
    "                        # User question: {user_question}\n",
    "\n",
    "                        # Context: \n",
    "                        \n",
    "                        ## Table summary: \n",
    "                        {found_table.table_summary}\n",
    "\n",
    "                        ## Table content: \n",
    "                        {found_table.table}\"\"\"\n",
    "\n",
    "    # initialize the OpenAI client with your API key\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # initialize the OpenAI client with your API key\n",
    "    answered_question = (\n",
    "        client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": question_prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "\n",
    "    return answered_question\n",
    "\n",
    "\n",
    "# generate the answer to the user's question\n",
    "# as context we using the first entry in the tables_df\n",
    "answered_question = build_prompt_and_generate_answer(\n",
    "    user_question=user_question, found_table=tables_df.iloc[0]\n",
    ")\n",
    "\n",
    "print(answered_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when a user is asking for information like that, we would attach the table to the prompt and the summary. The text snippet below shows how we can build a simple prompt using the table and the generated text summary to answer a user's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random question to the embedded table\n",
    "user_question = \"What are the education levels of the people working in Sales?\"\n",
    "\n",
    "\n",
    "def build_prompt_and_generate_answer(user_question, found_table):\n",
    "    \"\"\"\n",
    "    This function builds a prompt using the user's question and the context of the table\n",
    "    and generates an answer using the OpenAI API\n",
    "\n",
    "    Parameters:\n",
    "        user_question: the question asked by the user\n",
    "        found_table: the table context to generate the answer from\n",
    "\n",
    "    Returns:\n",
    "        answered_question: the answer to the user's question\n",
    "    \"\"\"\n",
    "    # define the question prompt\n",
    "    question_prompt = f\"\"\"You are an assistant using the content from PDFs \\\n",
    "                        to answer questions. Below you can find the \\\n",
    "                        user's question and relevant context. Please use the \\\n",
    "                        context to generate an answer to the user's question.\n",
    "                        \n",
    "                        # User question: {user_question}\n",
    "\n",
    "                        # Context: \n",
    "                        \n",
    "                        ## Table summary: \n",
    "                        {found_table.table_summary}\n",
    "\n",
    "                        ## Table content: \n",
    "                        {found_table.table}\"\"\"\n",
    "\n",
    "    # initialize the OpenAI client with your API key\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # initialize the OpenAI client with your API key\n",
    "    answered_question = (\n",
    "        client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": question_prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150,\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "\n",
    "    return answered_question\n",
    "\n",
    "\n",
    "# generate the answer to the user's question\n",
    "# as context we using the first entry in the tables_df\n",
    "answered_question = build_prompt_and_generate_answer(\n",
    "    user_question=user_question, found_table=tables_df.iloc[0]\n",
    ")\n",
    "\n",
    "print(answered_question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
